{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11579611,"sourceType":"datasetVersion","datasetId":7260372}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 0: Library Installation\n\n!pip install transformers>=4.42.0 datasets>=2.10.0 torch>=1.9.0 seqeval --quiet\n!pip install peft>=0.11.1 --quiet\n!pip install accelerate>=0.28.0 --quiet\n\nprint(\"Libraries installation complete.\")\n\n# Verify key versions after installation\nprint(\"\\n--- Verifying Versions ---\")\ntry:\n    import transformers\n    print(f\"Transformers version: {transformers.__version__}\")\nexcept ImportError: print(\"Transformers not found.\")\ntry:\n    import datasets\n    print(f\"Datasets version: {datasets.__version__}\")\nexcept ImportError: print(\"Datasets not found.\")\ntry:\n    import torch\n    print(f\"PyTorch version: {torch.__version__}\")\nexcept ImportError: print(\"PyTorch not found.\")\ntry:\n    import peft\n    print(f\"PEFT version: {peft.__version__}\")\nexcept ImportError: print(\"PEFT not found.\")\ntry:\n    import accelerate\n    print(f\"Accelerate version: {accelerate.__version__}\")\nexcept ImportError: print(\"Accelerate not found.\")\ntry:\n    import pandas as pd\n    print(f\"Pandas version: {pd.__version__}\")\nexcept ImportError: print(\"Pandas not found.\")\ntry:\n    import numpy as np\n    print(f\"Numpy version: {np.__version__}\")\nexcept ImportError: print(\"Numpy not found.\")\nprint(\"--- Verification Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T05:57:08.433117Z","iopub.execute_input":"2025-05-13T05:57:08.433338Z","iopub.status.idle":"2025-05-13T05:58:58.169100Z","shell.execute_reply.started":"2025-05-13T05:57:08.433316Z","shell.execute_reply":"2025-05-13T05:58:58.168306Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mLibraries installation complete.\n\n--- Verifying Versions ---\nTransformers version: 4.51.1\nDatasets version: 3.5.0\nPyTorch version: 2.5.1+cu124\n","output_type":"stream"},{"name":"stderr","text":"2025-05-13 05:58:47.357472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747115927.544858      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747115927.602702      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"PEFT version: 0.14.0\nAccelerate version: 1.3.0\nPandas version: 2.2.3\nNumpy version: 1.26.4\n--- Verification Complete ---\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"print(\"--- Step 1: Loading Data using pd.read_csv ---\")\n\nimport pandas as pd\nimport numpy as np\n\n# Paths Handling\nKAGGLE_INPUT_PATH = \"/kaggle/input/sem-eval-absa\"\nlaptop_train_path = f\"{KAGGLE_INPUT_PATH}/Laptop_Train_v2.csv\"\nresto_train_path = f\"{KAGGLE_INPUT_PATH}/Restaurants_Train_v2.csv\"\n\ntry:\n    print(f\"Attempting to load: {laptop_train_path}\")\n    df_laptop = pd.read_csv(laptop_train_path, encoding='ISO-8859-1', on_bad_lines='skip')\n    print(f\"Loaded {len(df_laptop)} laptop records.\")\n\n    print(f\"\\nAttempting to load: {resto_train_path}\")\n    df_resto = pd.read_csv(resto_train_path, encoding='ISO-8859-1', on_bad_lines='skip')\n    print(f\"Loaded {len(df_resto)} restaurant records.\")\n\n    # Combine the datasets\n    print(\"\\nCombining datasets...\")\n    df_laptop['domain'] = 'laptop'\n    df_resto['domain'] = 'restaurant'\n    df_combined_train = pd.concat([df_laptop, df_resto], ignore_index=True)\n\n    # Verify successful combination\n    print(f\"\\nTotal combined training instances: {len(df_combined_train)}\")\n    print(\"Combined DataFrame Info:\")\n    df_combined_train.info()\n    print(\"\\nCombined DataFrame Head:\")\n    print(df_combined_train.head())\n\n    print(\"\\n--- Dataset Loading Complete ---\")\n\nexcept FileNotFoundError:\n    print(f\"Error: Files not found. Please double-check the Kaggle dataset path and filenames.\")\n    print(f\"Expected paths:\\n{laptop_train_path}\\n{resto_train_path}\")\n    df_combined_train = None\nexcept Exception as e:\n    print(f\"An error occurred during data loading: {e}\")\n    import traceback\n    traceback.print_exc()\n    df_combined_train = None\n\n# Check if df_combined_train was successfully created\nif df_combined_train is not None and not df_combined_train.empty:\n    print(\"\\nData loading successful. Ready for Step 2 (Cleaning).\")\nelse:\n    print(\"\\nData loading failed. Please review errors above.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:01:55.976577Z","iopub.execute_input":"2025-05-13T06:01:55.977330Z","iopub.status.idle":"2025-05-13T06:01:56.050282Z","shell.execute_reply.started":"2025-05-13T06:01:55.977302Z","shell.execute_reply":"2025-05-13T06:01:56.049530Z"}},"outputs":[{"name":"stdout","text":"--- Step 1: Loading Data using pd.read_csv ---\nAttempting to load: /kaggle/input/sem-eval-absa/Laptop_Train_v2.csv\nLoaded 2358 laptop records.\n\nAttempting to load: /kaggle/input/sem-eval-absa/Restaurants_Train_v2.csv\nLoaded 3693 restaurant records.\n\nCombining datasets...\n\nTotal combined training instances: 6051\nCombined DataFrame Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6051 entries, 0 to 6050\nData columns (total 7 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   id           6051 non-null   int64 \n 1   Sentence     6051 non-null   object\n 2   Aspect Term  6051 non-null   object\n 3   polarity     6051 non-null   object\n 4   from         6051 non-null   int64 \n 5   to           6051 non-null   int64 \n 6   domain       6051 non-null   object\ndtypes: int64(3), object(4)\nmemory usage: 331.0+ KB\n\nCombined DataFrame Head:\n     id                                           Sentence     Aspect Term  \\\n0  2339  I charge it at night and skip taking the cord ...            cord   \n1  2339  I charge it at night and skip taking the cord ...    battery life   \n2  1316  The tech guy then said the service center does...  service center   \n3  1316  The tech guy then said the service center does...    \"sales\" team   \n4  1316  The tech guy then said the service center does...        tech guy   \n\n   polarity  from   to  domain  \n0   neutral    41   45  laptop  \n1  positive    74   86  laptop  \n2  negative    27   41  laptop  \n3  negative   109  121  laptop  \n4   neutral     4   12  laptop  \n\n--- Dataset Loading Complete ---\n\nData loading successful. Ready for Step 2 (Cleaning).\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(\"\\n--- Step 2: Initial Data Cleaning, Standardization, and Type Conversion ---\")\n\n# A copy to not modify the original data\ndf_cleaned = df_combined_train.copy()\n\n# Convert all column names to lowercase and replace spaces with underscores (standarization)\nprint(\"\\nStandardizing column names (lowercase, replace space with underscore)...\")\ndf_cleaned.columns = df_cleaned.columns.str.lower().str.replace(' ', '_', regex=False)\nprint(\"New column names:\", df_cleaned.columns.tolist())\n\n# Standardized column names\nessential_cols = ['aspect_term', 'polarity', 'from', 'to', 'sentence']\n\n# 1. Inspect types and missing values on combined data\nprint(\"\\nInfo before cleaning (after standardization):\")\ndf_cleaned.info()\n\n# 2. Handle Missing Values in essential columns\nprint(f\"\\nRows before dropping NaNs: {len(df_cleaned)}\")\n# Check if essential columns exist before trying to drop NaNs based on them\nmissing_essential = [col for col in essential_cols if col not in df_cleaned.columns]\nif missing_essential:\n    print(f\"Error: Essential columns missing for dropna: {missing_essential}\")\nelse:\n    df_cleaned.dropna(subset=essential_cols, inplace=True)\n    print(f\"Rows after dropping NaNs in essential columns: {len(df_cleaned)}\")\n\n# 3. Ensure Correct Numerical Types for 'from' and 'to'\n# Check if columns exist first\nif 'from' in df_cleaned.columns and 'to' in df_cleaned.columns:\n    # Check if they are already numeric before converting\n    if pd.api.types.is_numeric_dtype(df_cleaned['from']) and pd.api.types.is_numeric_dtype(df_cleaned['to']):\n        print(\"\\nConverting 'from' and 'to' columns to integer type...\")\n        try:\n            # Ensure no NaNs\n            df_cleaned['from'] = pd.to_numeric(df_cleaned['from'], errors='coerce').fillna(-1).astype(int)\n            df_cleaned['to'] = pd.to_numeric(df_cleaned['to'], errors='coerce').fillna(-1).astype(int)\n\n            print(\"'from' and 'to' columns successfully converted to int.\")\n        except Exception as e: # Catch broader exceptions during conversion\n            print(f\"Error converting 'from'/'to' to int: {e}. Check data.\")\n    else:\n        print(\"\\nWarning: 'from' or 'to' column is not purely numeric. Attempting coercion.\")\n        try:\n             df_cleaned['from'] = pd.to_numeric(df_cleaned['from'], errors='coerce').fillna(-1).astype(int)\n             df_cleaned['to'] = pd.to_numeric(df_cleaned['to'], errors='coerce').fillna(-1).astype(int)\n             print(\"Coercion and conversion to int attempted.\")\n        except Exception as e:\n             print(f\"Error during coercion/conversion of 'from'/'to' to int: {e}\")\n\nelse:\n    print(\"\\nError: 'from' or 'to' columns not found after standardization!\")\n\n\n# 4. Basic Text Cleaning (Remove leading/trailing whitespace)\n# Check if columns exist\nif 'sentence' in df_cleaned.columns and 'aspect_term' in df_cleaned.columns:\n    print(\"\\nApplying strip() to 'sentence' and 'aspect_term' columns...\")\n    df_cleaned['sentence'] = df_cleaned['sentence'].astype(str).str.strip()\n    df_cleaned['aspect_term'] = df_cleaned['aspect_term'].astype(str).str.strip()\nelse:\n    print(\"\\nError: 'sentence' or 'aspect_term' columns not found for stripping!\")\n\n\n# 5. Inspect Polarity Labels\nif 'polarity' in df_cleaned.columns:\n    print(\"\\nUnique polarity values found:\")\n    unique_polarities = df_cleaned['polarity'].unique()\n    print(unique_polarities)\n    # Define our final label set (important for later) - adjust based on output above\n    # We need to map these string labels to integers for the model\n    possible_labels = ['positive', 'negative', 'neutral', 'conflict']\n    label_map = {label: i for i, label in enumerate(possible_labels)}\nelse:\n    print(\"\\nError: 'polarity' column not found!\")\n\n# --- Verify the cleaned DataFrame ---\nprint(\"\\nCleaned DataFrame Info:\")\ndf_cleaned.info()\nprint(\"\\nCleaned DataFrame Head (Cleaned):\")\nprint(df_cleaned.head())\n\n# --- End of Cleaning Step ---\nprint(\"\\n--- Initial Cleaning, Standardization, and Type Conversion Complete ---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:02:00.034272Z","iopub.execute_input":"2025-05-13T06:02:00.035103Z","iopub.status.idle":"2025-05-13T06:02:00.066640Z","shell.execute_reply.started":"2025-05-13T06:02:00.035075Z","shell.execute_reply":"2025-05-13T06:02:00.066062Z"}},"outputs":[{"name":"stdout","text":"\n--- Step 2: Initial Data Cleaning, Standardization, and Type Conversion ---\n\nStandardizing column names (lowercase, replace space with underscore)...\nNew column names: ['id', 'sentence', 'aspect_term', 'polarity', 'from', 'to', 'domain']\n\nInfo before cleaning (after standardization):\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6051 entries, 0 to 6050\nData columns (total 7 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   id           6051 non-null   int64 \n 1   sentence     6051 non-null   object\n 2   aspect_term  6051 non-null   object\n 3   polarity     6051 non-null   object\n 4   from         6051 non-null   int64 \n 5   to           6051 non-null   int64 \n 6   domain       6051 non-null   object\ndtypes: int64(3), object(4)\nmemory usage: 331.0+ KB\n\nRows before dropping NaNs: 6051\nRows after dropping NaNs in essential columns: 6051\n\nConverting 'from' and 'to' columns to integer type...\n'from' and 'to' columns successfully converted to int.\n\nApplying strip() to 'sentence' and 'aspect_term' columns...\n\nUnique polarity values found:\n['neutral' 'positive' 'negative' 'conflict']\n\nCleaned DataFrame Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6051 entries, 0 to 6050\nData columns (total 7 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   id           6051 non-null   int64 \n 1   sentence     6051 non-null   object\n 2   aspect_term  6051 non-null   object\n 3   polarity     6051 non-null   object\n 4   from         6051 non-null   int64 \n 5   to           6051 non-null   int64 \n 6   domain       6051 non-null   object\ndtypes: int64(3), object(4)\nmemory usage: 331.0+ KB\n\nCleaned DataFrame Head (Cleaned):\n     id                                           sentence     aspect_term  \\\n0  2339  I charge it at night and skip taking the cord ...            cord   \n1  2339  I charge it at night and skip taking the cord ...    battery life   \n2  1316  The tech guy then said the service center does...  service center   \n3  1316  The tech guy then said the service center does...    \"sales\" team   \n4  1316  The tech guy then said the service center does...        tech guy   \n\n   polarity  from   to  domain  \n0   neutral    41   45  laptop  \n1  positive    74   86  laptop  \n2  negative    27   41  laptop  \n3  negative   109  121  laptop  \n4   neutral     4   12  laptop  \n\n--- Initial Cleaning, Standardization, and Type Conversion Complete ---\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"\\n--- Step 3: Aggregate Aspects per Sentence using Unique ID ---\")\n\n# --- Create a globally unique sentence identifier ---\n# Combine domain and original ID to create a unique key\n# Ensure 'id' is string for concatenation, handle potential non-existence\nif 'id' in df_cleaned.columns and 'domain' in df_cleaned.columns:\n    print(\"\\nCreating unique sentence identifier (domain_id)...\")\n    df_cleaned['unique_id'] = df_cleaned['domain'] + '_' + df_cleaned['id'].astype(str)\n    print(\"Unique ID created.\")\n    # Verify number of unique IDs vs original IDs\n    print(f\"Unique IDs created: {df_cleaned['unique_id'].nunique()}\")\n    print(f\"Original IDs count: {df_cleaned['id'].nunique()}\") # Should be roughly half if IDs repeat across domains\nelse:\n    print(\"Error: Cannot create unique_id. 'id' or 'domain' column missing.\")\n    df_cleaned['unique_id'] = None # Avoid error later, but signals problem\n\n# Define the function to apply to each sentence group (same as before)\ndef aggregate_aspects_per_sentence(group):\n    required_cols = ['sentence', 'aspect_term', 'polarity', 'from', 'to', 'domain']\n    if not all(col in group.columns for col in required_cols):\n         print(f\"Warning: Skipping group due to missing columns. Group keys: {group.name}\")\n         return None\n\n    aspect_list = []\n    for _, row in group.iterrows():\n        aspect_list.append({\n            'term': row['aspect_term'],\n            'polarity': row['polarity'],\n            'from': row['from'],\n            'to': row['to']\n        })\n    # Take sentence and domain from the first row\n    # Keep the original ID as well if needed, though unique_id is the key now\n    result = pd.Series({\n        'original_id': group['id'].iloc[0], # Keep original ID for reference\n        'sentence': group['sentence'].iloc[0],\n        'aspects': aspect_list,\n        'domain': group['domain'].iloc[0]\n    })\n    return result\n\n# Group by the NEW 'unique_id' column\nprint(f\"\\nGrouping by 'unique_id' and aggregating aspects...\")\nif 'unique_id' in df_cleaned.columns and df_cleaned['unique_id'].notna().all():\n    aggregated_data_series = df_cleaned.groupby('unique_id').apply(aggregate_aspects_per_sentence)\n    aggregated_data_series = aggregated_data_series.dropna()\n    aggregated_df = aggregated_data_series.reset_index() # unique_id becomes a column\n    print(f\"Number of unique sentences after aggregation: {len(aggregated_df)}\")\nelse:\n    print(\"Error: 'unique_id' column not found or contains NaNs. Cannot group.\")\n    aggregated_df = pd.DataFrame()\n\n\n# Check the result\nif not aggregated_df.empty:\n    print(\"\\nAggregated DataFrame Head:\")\n    print(aggregated_df.head()) # Note the new 'unique_id' and 'original_id' columns\n\n    # Find and print the example that had ID 3 from laptops\n    print(\"\\nExample for original Laptop ID 3:\")\n    laptop_example_3 = aggregated_df[(aggregated_df['original_id'] == 3) & (aggregated_df['domain'] == 'laptop')]\n    if not laptop_example_3.empty:\n         print(laptop_example_3.iloc[0]['sentence'])\n         print(laptop_example_3.iloc[0]['aspects'])\n    else:\n         print(\"Laptop example with ID 3 not found in aggregated data (might have been dropped if it had NaNs).\")\n\n\n    # --- Convert to Hugging Face Dataset object ---\n    print(\"\\nConverting aggregated DataFrame to Hugging Face Dataset...\")\n    from datasets import Dataset, DatasetDict\n\n    # Rename columns if needed, or select specific ones\n    # Let's keep unique_id, sentence, aspects, domain\n    columns_to_keep = ['unique_id', 'sentence', 'aspects', 'domain'] # Exclude original_id if not needed for tokenization\n    hf_dataset = Dataset.from_pandas(aggregated_df[columns_to_keep])\n\n    print(\"\\nHugging Face Dataset Info:\")\n    print(hf_dataset)\n    print(\"\\nSample record from Hugging Face Dataset:\")\n    print(hf_dataset[0])\n\nelse:\n    print(\"\\nAggregated DataFrame is empty, cannot proceed to Dataset conversion.\")\n\n\n# --- End of Aggregation Step ---\nprint(\"\\n--- Aggregation (Revised) Complete ---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:02:05.050537Z","iopub.execute_input":"2025-05-13T06:02:05.050853Z","iopub.status.idle":"2025-05-13T06:02:06.609131Z","shell.execute_reply.started":"2025-05-13T06:02:05.050823Z","shell.execute_reply":"2025-05-13T06:02:06.608305Z"}},"outputs":[{"name":"stdout","text":"\n--- Step 3 (Revised): Aggregate Aspects per Sentence using Unique ID ---\n\nCreating unique sentence identifier (domain_id)...\nUnique ID created.\nUnique IDs created: 3509\nOriginal IDs count: 2687\n\nGrouping by 'unique_id' and aggregating aspects...\nNumber of unique sentences after aggregation: 3509\n\nAggregated DataFrame Head:\n     unique_id  original_id  \\\n0   laptop_100          100   \n1  laptop_1001         1001   \n2  laptop_1008         1008   \n3   laptop_101          101   \n4  laptop_1012         1012   \n\n                                            sentence  \\\n0  I had of course bought a 3 year warranty, so I...   \n1  But sadly the replacement froze-up while updat...   \n2           Ive had to call tech support many times.   \n3  I got assurances from 2 different people that ...   \n4                     I had to pay for the shipping!   \n\n                                             aspects  domain  \n0  [{'term': '3 year warranty', 'polarity': 'neut...  laptop  \n1  [{'term': 'BIOS', 'polarity': 'negative', 'fro...  laptop  \n2  [{'term': 'tech support', 'polarity': 'neutral...  laptop  \n3  [{'term': 'warranty', 'polarity': 'positive', ...  laptop  \n4  [{'term': 'shipping', 'polarity': 'negative', ...  laptop  \n\nExample for original Laptop ID 3:\nIt's so nice to look at and the keys are easy to type with.\n[{'term': 'keys', 'polarity': 'positive', 'from': 32, 'to': 36}, {'term': 'look', 'polarity': 'positive', 'from': 16, 'to': 20}]\n\nConverting aggregated DataFrame to Hugging Face Dataset...\n\nHugging Face Dataset Info:\nDataset({\n    features: ['unique_id', 'sentence', 'aspects', 'domain'],\n    num_rows: 3509\n})\n\nSample record from Hugging Face Dataset:\n{'unique_id': 'laptop_100', 'sentence': 'I had of course bought a 3 year warranty, so I sent it in to be replaced and (almost 2 months later) the dv4 is what the sent me as a replacement.', 'aspects': [{'from': 25, 'polarity': 'neutral', 'term': '3 year warranty', 'to': 40}], 'domain': 'laptop'}\n\n--- Aggregation (Revised) Complete ---\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/2978610388.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  aggregated_data_series = df_cleaned.groupby('unique_id').apply(aggregate_aspects_per_sentence)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(\"\\n--- Starting Consolidated Steps 4-7 ---\")\n\nimport torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    DataCollatorForTokenClassification,\n    AutoModelForTokenClassification,\n    TrainingArguments,\n    Trainer\n)\nfrom datasets import Dataset, DatasetDict\nimport pandas as pd\nimport numpy as np\ntry:\n    from seqeval.metrics import classification_report, accuracy_score\n    SEQEVAL_AVAILABLE = True\n    print(\"seqeval imported successfully.\")\nexcept ImportError:\n    print(\"Warning: seqeval library not found. Metrics calculation will be basic.\")\n    SEQEVAL_AVAILABLE = False\n    # Define dummy functions if seqeval not found to avoid NameError\n    def classification_report(y_true, y_pred, output_dict=True, zero_division=0): return {}\n    def accuracy_score(y_true, y_pred): return 0.0\n\n\n# --- Step 4: Define Labeling Scheme, Load Tokenizer, Define Alignment ---\nprint(\"\\n--- Running Step 4 ---\")\nlabel_list = [\"O\", \"B-ASP\", \"I-ASP\"]\nlabel2id = {label: i for i, label in enumerate(label_list)}\nid2label = {i: label for i, label in enumerate(label_list)}\nnum_labels = len(label_list)\nMODEL_NAME = \"bert-base-uncased\"\nprint(f\"Labels: {label_list}\")\nprint(f\"Loading Tokenizer ({MODEL_NAME})...\")\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=num_labels, id2label=id2label, label2id=label2id) # Define config here\n    print(\"Tokenizer and Config loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error loading tokenizer/config: {e}\")\n    tokenizer = None; config = None\n\ndef tokenize_and_align_labels(examples, tkz, lbl2id, label_all_tokens=False):\n    \"\"\" Implements tokens' BIO tagging \"\"\"\n    tokenized_inputs = tkz(examples[\"sentence\"], truncation=True, is_split_into_words=False, max_length=512, return_offsets_mapping=True)\n    all_labels = []\n    # Iterates over the known aspects\n    for i, offset_mapping in enumerate(tokenized_inputs[\"offset_mapping\"]):\n        aspects_in_doc = examples[\"aspects\"][i]\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        label_ids = [-100 if word_id is None else lbl2id[\"O\"] for word_id in word_ids]\n        # Iterates over all BERT tokens of the sentence for the current aspect\n        for aspect in aspects_in_doc:\n            asp_start_char = aspect['from']; asp_end_char = aspect['to']\n            token_start_index = -1\n            for idx, (start, end) in enumerate(offset_mapping):\n                if start == end == 0: continue\n                if (start < asp_end_char) and (end > asp_start_char):\n                    if token_start_index == -1:\n                        is_first_word_token = True; current_word_id = word_ids[idx]\n                        if current_word_id is not None and idx > 0:\n                             prev_word_id = word_ids[idx-1]\n                             if prev_word_id == current_word_id: is_first_word_token = False\n                        if start >= asp_start_char and is_first_word_token:\n                            if label_ids[idx] == lbl2id[\"O\"]: label_ids[idx] = lbl2id[\"B-ASP\"]\n                            token_start_index = idx\n                        elif label_ids[idx] == lbl2id[\"O\"]:\n                            label_ids[idx] = lbl2id[\"I-ASP\"]\n                            if token_start_index == -1: token_start_index = idx\n                    elif label_ids[idx] == lbl2id[\"O\"]: label_ids[idx] = lbl2id[\"I-ASP\"]\n        if not label_all_tokens:\n            final_aligned_labels = []; last_word_id = None\n            for idx, word_id in enumerate(word_ids):\n                if word_id is None: final_aligned_labels.append(-100)\n                elif word_id == last_word_id: final_aligned_labels.append(-100)\n                else: final_aligned_labels.append(label_ids[idx])\n                last_word_id = word_id\n            all_labels.append(final_aligned_labels)\n        else: all_labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = all_labels\n    return tokenized_inputs\n\nprint(\"\\nApplying tokenization and label alignment...\")\ntokenized_dataset = None\nif 'hf_dataset' in locals() and hf_dataset and tokenizer:\n    try:\n        tokenized_dataset = hf_dataset.map(tokenize_and_align_labels, batched=True, fn_kwargs={'tkz': tokenizer, 'lbl2id': label2id, 'label_all_tokens': False}, remove_columns=hf_dataset.column_names)\n        print(\"Tokenization complete.\")\n    except Exception as e: print(f\"Error during .map(): {e}\")\nelse: print(\"Error: hf_dataset or tokenizer missing.\")\n\nprint(\"\\nInitializing Data Collator...\")\nif tokenizer: data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer); print(\"Data Collator initialized.\")\nelse: data_collator = None; print(\"Error: Tokenizer missing.\")\n\nprint(\"\\nSplitting dataset...\")\ndataset_splits = None\nif tokenized_dataset:\n    try:\n        train_testvalid = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n        test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n        dataset_splits = DatasetDict({'train': train_testvalid['train'], 'validation': test_valid['train'], 'test': test_valid['test']})\n        print(\"Dataset splits created:\", dataset_splits)\n    except Exception as e: print(f\"Error splitting dataset: {e}\")\nelse: print(\"Cannot split dataset.\")\nprint(\"\\n--- Step 4 Complete ---\")\n\n# --- Step 5: Defining Evaluation Metrics ---\nprint(\"\\n--- Step 5: Defining Evaluation Metrics ---\")\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=2)\n    true_labels = []; true_predictions = []\n    # Iterate through each sequence in the batch\n    for prediction_seq, label_seq in zip(predictions, labels):\n        seq_true_labels = []; seq_true_preds = []\n        # Iterate through tokens in the current sequence\n        for pred, label in zip(prediction_seq, label_seq):\n            if label != -100:\n                 if label in id2label and pred in id2label:\n                     seq_true_labels.append(id2label[label])\n                     seq_true_preds.append(id2label[pred])\n        if seq_true_labels:\n             true_labels.append(seq_true_labels)\n             true_predictions.append(seq_true_preds)\n    # If no valid labels found in the batch, return zeros\n    if not true_labels or not SEQEVAL_AVAILABLE: return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n    results = {}\n    try:\n        report = classification_report(true_labels, true_predictions, output_dict=True, zero_division=0)\n        results[\"precision\"] = report.get(\"micro avg\", {}).get(\"precision\", 0.0)\n        results[\"recall\"] = report.get(\"micro avg\", {}).get(\"recall\", 0.0)\n        results[\"f1\"] = report.get(\"micro avg\", {}).get(\"f1-score\", 0.0)\n        if \"ASP\" in report: results[\"f1_ASP\"] = report[\"ASP\"].get(\"f1-score\", 0.0)\n    except Exception as e: print(f\"Error calculating report: {e}\"); results = {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n    return results\nprint(\"compute_metrics function defined.\")\nprint(\"\\n--- Step 5 Complete ---\")\n\n# --- Step 6: Configure Training Arguments ---\nprint(\"\\n--- Step 6: Configure Training Arguments (Simplest Working Version) ---\")\nargs = None\nif 'dataset_splits' in locals() and dataset_splits:\n    TRAIN_BATCH_SIZE = 16; NUM_EPOCHS = 3; LEARNING_RATE = 2e-5\n    OUTPUT_DIR = \"/kaggle/working/bert-base-uncased-absa-consolidated\"\n    args = TrainingArguments(\n        output_dir=OUTPUT_DIR, \n        num_train_epochs=NUM_EPOCHS, \n        learning_rate=LEARNING_RATE,\n        per_device_train_batch_size=TRAIN_BATCH_SIZE, \n        per_device_eval_batch_size=TRAIN_BATCH_SIZE,\n        weight_decay=0.01, \n        report_to=\"none\", \n        save_steps=500, \n        logging_steps=100,\n        load_best_model_at_end=False\n    )\n    print(\"TrainingArguments configured\")\nelse: print(\"Error: dataset_splits missing. Cannot configure TrainingArguments.\")\nprint(\"\\n--- Step 6 Complete ---\")\n\n# --- Step 7: Instantiate the Trainer ---\nprint(\"\\n--- Step 7: Instantiate the Trainer ---\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\ntrainer = None\n\n# Check before Trainer instantiation\nfinal_check_vars = {'model_config': config, 'training_args': args, 'datasets': dataset_splits, 'tkz': tokenizer, 'collator': data_collator, 'metrics_func': compute_metrics}\nif all(v is not None for v in final_check_vars.values()):\n    try:\n        print(f\"\\nLoading model ({MODEL_NAME}) for Token Classification...\")\n        model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config)\n        model.to(device)\n        print(f\"Model loaded and moved to {device}\")\n\n        print(\"\\nInstantiating Trainer...\")\n        trainer = Trainer(\n            model=model,\n            args=args,\n            train_dataset=dataset_splits[\"train\"],\n            eval_dataset=dataset_splits[\"validation\"],\n            tokenizer=tokenizer,\n            data_collator=data_collator,\n            compute_metrics=compute_metrics\n        )\n        print(\"Trainer instantiated successfully.\")\n\n    except Exception as e:\n        print(f\"Error during model loading or Trainer instantiation: {e}\")\n        import traceback\n        traceback.print_exc()\nelse:\n    print(\"Error: One or more required components were None before Trainer instantiation. Check previous steps.\")\n    print({k: \"Exists\" if v is not None else \"MISSING/NONE\" for k, v in final_check_vars.items()})\n\n\nprint(\"\\n--- Consolidated Steps 4-7 Complete ---\")\n\n# Check if trainer was created\nif 'trainer' in locals() and trainer is not None:\n    print(\"\\n Trainer object created successfully!\")\nelse:\n    print(\"\\n Trainer object creation failed. Please review errors above.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:02:23.322482Z","iopub.execute_input":"2025-05-13T06:02:23.323159Z","iopub.status.idle":"2025-05-13T06:02:31.873269Z","shell.execute_reply.started":"2025-05-13T06:02:23.323126Z","shell.execute_reply":"2025-05-13T06:02:31.872485Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Consolidated Steps 4-7 ---\nseqeval imported successfully.\n\n--- Running Step 4 ---\nLabels: ['O', 'B-ASP', 'I-ASP']\nLoading Tokenizer (bert-base-uncased)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a9db3f6543942c0baa40fd2fb6cb539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c087bdceb77748d594e0e0cd8d2ca493"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b8d6113b6844fbb8635b9769b9d6f4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76277f23af554fc895521fdc131065ce"}},"metadata":{}},{"name":"stdout","text":"Tokenizer and Config loaded successfully.\n\nApplying tokenization and label alignment...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3509 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d264ec8a98444ea9621c6504c904350"}},"metadata":{}},{"name":"stdout","text":"Tokenization complete.\n\nInitializing Data Collator...\nData Collator initialized.\n\nSplitting dataset...\nDataset splits created: DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels'],\n        num_rows: 2807\n    })\n    validation: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels'],\n        num_rows: 351\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels'],\n        num_rows: 351\n    })\n})\n\n--- Step 4 Complete ---\n\n--- Step 5: Defining Evaluation Metrics ---\ncompute_metrics function defined.\n\n--- Step 5 Complete ---\n\n--- Step 6: Configure Training Arguments (Simplest Working Version) ---\nTrainingArguments configured (Simplest Version + Save/Log Steps).\n\n--- Step 6 Complete ---\n\n--- Step 7: Instantiate the Trainer ---\nUsing device: cuda\n\nLoading model (bert-base-uncased) for Token Classification...\n","output_type":"stream"},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd2221d8fb3f421da868f4ec5cd9b975"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded and moved to cuda\n\nInstantiating Trainer...\nTrainer instantiated successfully.\n\n--- Consolidated Steps 4-7 Complete ---\n\n Trainer object created successfully! Ready for Step 8 (Training).\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1998149807.py:173: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(\"\\n--- Step 8: Start Fine-Tuning ---\")\n\nif 'trainer' in locals() and trainer is not None:\n    try:\n        print(\"\\nStarting training...\")\n        # Start the training loop\n        train_result = trainer.train()\n        print(\"\\nTraining finished!\")\n\n        # Save final metrics and state\n        metrics = train_result.metrics\n        trainer.log_metrics(\"train\", metrics)\n        trainer.save_metrics(\"train\", metrics)\n        trainer.save_state()\n\n        print(\"\\nFinal training metrics logged and saved.\")\n        print(metrics) # Print metrics\n\n    except Exception as e:\n        print(f\"\\nAn error occurred during training: {e}\")\n        import traceback\n        traceback.print_exc()\n\nelse:\n    print(\"Error: Trainer object not found or not instantiated successfully. Cannot start training.\")\n\n\n# --- End of Fine-Tuning Step ---\nprint(\"\\n--- Fine-Tuning Process Attempted ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:02:36.160686Z","iopub.execute_input":"2025-05-13T06:02:36.161513Z","iopub.status.idle":"2025-05-13T06:03:33.303554Z","shell.execute_reply.started":"2025-05-13T06:02:36.161477Z","shell.execute_reply":"2025-05-13T06:03:33.302994Z"}},"outputs":[{"name":"stdout","text":"\n--- Step 8: Start Fine-Tuning ---\n\nStarting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [528/528 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.273900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.114700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.085400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.073700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.053000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nTraining finished!\n***** train metrics *****\n  epoch                    =        3.0\n  total_flos               =   183333GF\n  train_loss               =     0.1169\n  train_runtime            = 0:00:56.70\n  train_samples_per_second =    148.512\n  train_steps_per_second   =      9.312\n\nFinal training metrics logged and saved.\n{'train_runtime': 56.7023, 'train_samples_per_second': 148.512, 'train_steps_per_second': 9.312, 'total_flos': 196852651406082.0, 'train_loss': 0.11687352711504156, 'epoch': 3.0}\n\n--- Fine-Tuning Process Attempted ---\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(\"\\n--- Step 9: Evaluation ---\")\n\nif ('trainer' in locals() and trainer is not None and\n    'dataset_splits' in locals() and dataset_splits is not None and\n    'validation' in dataset_splits):\n\n    print(\"\\nEvaluating on the validation set...\")\n    try:\n        eval_results = trainer.evaluate() # Runs evaluation on dataset_splits['validation']\n\n        # Save validation metrics\n        trainer.log_metrics(\"eval\", eval_results)\n        trainer.save_metrics(\"eval\", eval_results)\n\n        print(\"\\nValidation Set Evaluation Results:\")\n        print(eval_results)\n        \n    except Exception as e:\n        print(f\"An error occurred during validation set evaluation: {e}\")\n        import traceback\n        traceback.print_exc()\n\n    # --- Evaluate on the Test Set ---\n    if 'test' in dataset_splits:\n        print(\"\\nEvaluating on the test set...\")\n        try:\n            test_results = trainer.evaluate(eval_dataset=dataset_splits['test'])\n\n            # Save test metrics\n            trainer.log_metrics(\"test\", test_results)\n            trainer.save_metrics(\"test\", test_results)\n\n            print(\"\\nTest Set Evaluation Results:\")\n            test_metrics_renamed = {f\"test_{k.replace('eval_', '')}\": v for k, v in test_results.items()}\n            print(test_metrics_renamed)\n\n        except Exception as e:\n            print(f\"An error occurred during test set evaluation: {e}\")\n            import traceback\n            traceback.print_exc()\n    else:\n        print(\"\\nTest set not found in dataset_splits. Skipping test set evaluation.\")\n\nelse:\n    print(\"Error: Trainer object or validation dataset not found. Cannot perform evaluation.\")\n\nprint(\"\\n--- Evaluation Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T04:10:24.552995Z","iopub.execute_input":"2025-04-30T04:10:24.553703Z","iopub.status.idle":"2025-04-30T04:10:25.930219Z","shell.execute_reply.started":"2025-04-30T04:10:24.553675Z","shell.execute_reply":"2025-04-30T04:10:25.929652Z"}},"outputs":[{"name":"stdout","text":"\n--- Step 9: Evaluation ---\n\nEvaluating on the validation set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='44' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [22/22 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =        3.0\n  eval_f1                 =     0.8163\n  eval_f1_ASP             =     0.8163\n  eval_loss               =     0.1131\n  eval_precision          =     0.7837\n  eval_recall             =     0.8517\n  eval_runtime            = 0:00:00.72\n  eval_samples_per_second =    482.764\n  eval_steps_per_second   =     30.259\n\nValidation Set Evaluation Results:\n{'eval_loss': 0.11309386044740677, 'eval_precision': 0.7837423312883436, 'eval_recall': 0.8516666666666667, 'eval_f1': 0.8162939297124601, 'eval_f1_ASP': 0.8162939297124601, 'eval_runtime': 0.7271, 'eval_samples_per_second': 482.764, 'eval_steps_per_second': 30.259, 'epoch': 3.0}\n\nEvaluating on the test set...\n***** test metrics *****\n  epoch                   =        3.0\n  eval_f1                 =     0.8381\n  eval_f1_ASP             =     0.8381\n  eval_loss               =     0.0952\n  eval_precision          =     0.8085\n  eval_recall             =     0.8699\n  eval_runtime            = 0:00:00.63\n  eval_samples_per_second =    554.157\n  eval_steps_per_second   =     34.733\n\nTest Set Evaluation Results:\n{'test_loss': 0.09523133933544159, 'test_precision': 0.8084772370486656, 'test_recall': 0.8699324324324325, 'test_f1': 0.838079739625712, 'test_f1_ASP': 0.838079739625712, 'test_runtime': 0.6334, 'test_samples_per_second': 554.157, 'test_steps_per_second': 34.733, 'test_epoch': 3.0}\n\n--- Evaluation Complete ---\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(\"\\n--- Step 10: Saving Model & Inference Pipeline ---\")\n\nfrom transformers import pipeline\n\n# --- 1. Save the Fine-Tuned Model and Tokenizer ---\nfinal_model_output_dir = \"/kaggle/working/bert-absa-fine-tuned-final\"\n\nprint(f\"\\nSaving the fine-tuned model and tokenizer to: {final_model_output_dir}\")\n\nif 'trainer' in locals() and trainer is not None and 'tokenizer' in locals() and tokenizer is not None:\n    try:\n        trainer.save_model(final_model_output_dir) # Saves model weights and config\n        tokenizer.save_pretrained(final_model_output_dir) # Saves tokenizer files\n        print(\"Model and tokenizer saved successfully.\")\n    except Exception as e:\n        print(f\"Error saving model/tokenizer: {e}\")\nelse:\n    print(\"Error: Trainer or Tokenizer object not found. Cannot save.\")\n\n\n# --- 2. Create Inference Pipeline ---\n# Use the Hugging Face pipeline in token classification inference\n\nprint(\"\\nCreating inference pipeline...\")\n\nif ('AutoModelForTokenClassification' in locals() or 'transformers' in locals()) and \\\n   ('AutoTokenizer' in locals() or 'transformers' in locals()) and \\\n   ('id2label' in locals()):\n\n    try:\n        # Load the model and tokenizer we just saved\n        loaded_model = AutoModelForTokenClassification.from_pretrained(final_model_output_dir)\n        loaded_tokenizer = AutoTokenizer.from_pretrained(final_model_output_dir)\n\n        # Create the token-classification pipeline\n        device_id = 0 if torch.cuda.is_available() else -1\n        absa_pipeline = pipeline(\n            \"token-classification\",\n            model=loaded_model,\n            tokenizer=loaded_tokenizer,\n            aggregation_strategy=\"simple\",\n            device=device_id \n        )\n        print(\"Inference pipeline created successfully.\")\n\n        # --- 3. Test Inference ---\n        print(\"\\nTesting inference pipeline on example sentences:\")\n        test_sentences = [\n            \"The battery life is amazing, but the screen is hard to see.\",\n            \"Great price and camera quality.\",\n            \"Service was slow and the food was just okay.\"\n        ]\n\n        for sentence in test_sentences:\n            print(f\"\\nInput: '{sentence}'\")\n            try:\n                outputs = absa_pipeline(sentence)\n                # The pipeline output gives entities directly\n                extracted_aspects = [\n                    {\"term\": entity['word'], \"score\": entity['score']}\n                    for entity in outputs if entity['entity_group'] == 'ASP' # Assuming group name matches B-ASP/I-ASP pattern\n                ]\n                print(f\"Extracted Aspects: {extracted_aspects}\")\n            except Exception as e:\n                print(f\"Error during pipeline inference: {e}\")\n\n    except Exception as e:\n        print(f\"Error creating or using inference pipeline: {e}\")\n        absa_pipeline = None\n\nelse:\n    print(\"Error: Could not create pipeline due to missing components (Model, Tokenizer, or id2label).\")\n    absa_pipeline = None\n\nprint(\"\\n--- Model Saving and Inference Testing Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:03:33.304721Z","iopub.execute_input":"2025-05-13T06:03:33.305056Z","iopub.status.idle":"2025-05-13T06:03:34.935099Z","shell.execute_reply.started":"2025-05-13T06:03:33.305037Z","shell.execute_reply":"2025-05-13T06:03:34.934182Z"}},"outputs":[{"name":"stdout","text":"\n--- Step 10: Saving Model & Inference Pipeline ---\n\nSaving the fine-tuned model and tokenizer to: /kaggle/working/bert-absa-fine-tuned-final\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Model and tokenizer saved successfully.\n\nCreating inference pipeline...\nInference pipeline created successfully.\n\nTesting inference pipeline on example sentences:\n\nInput: 'The battery life is amazing, but the screen is hard to see.'\nExtracted Aspects: [{'term': 'battery life', 'score': 0.9935806}, {'term': 'screen', 'score': 0.9953557}]\n\nInput: 'Great price and camera quality.'\nExtracted Aspects: [{'term': 'price', 'score': 0.9944055}, {'term': 'camera quality', 'score': 0.7932142}]\n\nInput: 'Service was slow and the food was just okay.'\nExtracted Aspects: [{'term': 'service', 'score': 0.9977319}, {'term': 'food', 'score': 0.99815565}]\n\n--- Model Saving and Inference Testing Complete ---\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# --- Download output files ---\nimport os\n\nprint(\"\\n--- Downloading Output Files ---\")\n\nfolder_to_download = \"bert-absa-fine-tuned-final\" # Saved to\narchive_name = \"bert-absa-fine-tuned-final.tar.gz\" # Output archive name\noutput_path = f\"/kaggle/working/{folder_to_download}\"\n\nif os.path.exists(output_path):\n    print(f\"Compressing '{folder_to_download}' into '{archive_name}'...\")\n    # Use tar command to create a compressed archive\n    !tar -czf {archive_name} -C /kaggle/working/ {folder_to_download}\n    print(f\"Archive '{archive_name}' created in /kaggle/working/. You can download it from the Kaggle sidebar (Data -> Output).\")\nelse:\n    print(f\"Error: Folder '{output_path}' not found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T04:22:09.660119Z","iopub.execute_input":"2025-04-30T04:22:09.660769Z","iopub.status.idle":"2025-04-30T04:22:33.793249Z","shell.execute_reply.started":"2025-04-30T04:22:09.660744Z","shell.execute_reply":"2025-04-30T04:22:33.792387Z"}},"outputs":[{"name":"stdout","text":"\n--- Downloading Output Files ---\nCompressing 'bert-absa-fine-tuned-final' into 'bert-absa-fine-tuned-final.tar.gz'...\nArchive 'bert-absa-fine-tuned-final.tar.gz' created in /kaggle/working/. You can download it from the Kaggle sidebar (Data -> Output).\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}